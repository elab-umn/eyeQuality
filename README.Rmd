---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# eyeQuality

<!-- badges: start -->
<!-- badges: end -->

The goal of *eyeQuality* is to provide functions for basic processing 
of eye tracking data. 
The package is designed to support a variety of eye tracking data sources (but
was primarily tested using data exports from Tobii Studio and Tobii Pro). 


## Installation
You can install the eyeQuality from [GitHub](https://github.com/elab-umn/eyeQuality/) with:

``` r
# install.packages("devtools")
devtools::install_github("elab-umn/eyeQuality")
```

Alternatively, you can install from source by downloading the package via github. Follow instructions outlined [here](https://www.dataquest.io/blog/install-package-r/)


NOTE: Coming soon, we hope *eyeQuality* will be available to download via CRAN. We will update documentation here once available! 

## Package Documentation
To access package documentation and a list of all functions run 
``` r
help(package = "eyeQuality")
```



## Contributing
1. Clone github repo
1. Open the eyeQuality.Rproj file to launch the project in RStudio
1. Create a new branch (use the button on the "Git" pane in RStudio or use 
git commands in the Terminal)
1. Write code
1. Add tests using testthat package (see [tests/README](/tests/README.md))
1. Add documentation using roxygen (see [R package roxygen instructions](https://r-pkgs.org/man.html))
1. Once your changes are ready to be merged, submit a [pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) on github

If you find any bugs or have feature requests, [open an issue on github](https://github.com/elab-umn/eyetrackingELabR/issues). 
Please be as detailed as possible in your issue.

## Getting started

``` r
library(eyeQuality)
```

**eyeQuality** has a number of functions, but majority of these functions allow the pipeline to clean and categorize the data as listed. There are two main functions that most users will use. 

* `run_preprocessing()` is a function that takes a single input file and preprocesses it using the eyetracking pipeline
* `batch_preprocess()` takes a directory and preprocesses all of the files in that directory using the eyetracking pipeline. Data should be organized in a BIDS-like structure, such that the directory you provide has a list of directories for each participant, and each participant directory has a subdirectory for each visit or timepoint. 
* `generatedEyeTrackingPlots()` will take preprocessed data from one of the output files and generate three different standard plots (1) a plot of the raw gaze data from gaze X, gaze Y, dist Z, and pupil diameter (2) a heatmap of gaze distribution and (3) a simplified output of the processed gaze data with background-filled regions for the IVT classification. 

All of the functions are publicly available, in the case that you may want to apply your own data pipeline.

Additionally, the function `mapData()` can be updated to handle data from different eye tracking manufacturers software (the package currently supports Tobii Studio and Tobii Pro). This function simply standardized the naming of all of the 

## Example Workflow

Before running the **eyeQuality** pipeline, we recommend organizing your dataset into a BIDS like format. This means you have a top-level directory for you dataset. Within this top level directory, there is a directory for each participant (or subject directory), and a subdirectory for each timepoint or visit (or session directory) for the participant. The session directories should contain all of the raw eyetracking data files downloaded from the collection software. 

There are additional sidecar files like `dataset_description.json`, `participants.tsv`, and `scans.tsv` that describe the data on a dataset, participant, and session level, adding relevant metadata for the data sets. We recommend creating these files, but they are not required to process data via **eyeQuality**. 

``` r
library(eyeQuality)

#set working directory to top-level directory for dataset
setwd("/path/to/dataset/directory")

#get the list of files in your BIDS directory
list_bids_files(".") 
#set `subject_pattern` and `session_pattern` and `modality_pattern` if different than default

#run a specific file to verify the package runs on your data------------
run_preprocess(
  "sub-10001/ses-02/sub-10001_ses-02_task-A1nameOfTask_eyetrack.tsv",
  display.dimx = 594,
  display.dimy = 344,
  savedata = TRUE,
  batchName = "test"
)

#batch process-----------------------------------
# process data in the working directory with standard defaults
batch_preprocess(".", batch_name = "run1") 
# process data in the working directory with dimensions (in mm) for a square screen
batch_preprocess(".", batch_name = "run2", display.dimx = 344, display.dimy = 344) 
batch_preprocess(".", "trial1", firstInd = 1, lastInd = 1) # process a single trial based on the eyetracking events

list_bids_derivative_files(".") # show the full list of processed data
```

## Output Variable Data Dictionary
```{r dataDict, echo = FALSE, warning=FALSE}
library(knitr)

#Basic recording information definitions
recording_Variables <- c("event", "eventValue", "recordingDuration_ms", 
                         "resolutionHeight", "resolutionWidth", "eyeTrackerTimestamp",
                         "recordingTimestamp_ms")
recording_Definitions <- c("Stimulus event label", "Stimulus event value", "Total recording duration (ms)",
                           "Recording screen resolution height (px)", "Recording screen resolution width (px)",
                           "Internal eye tracker timestamp (unit?)", "Recording timecourse timestamp (ms)")

recording_Table <- data.frame(recording_Variables, recording_Definitions)
kable(recording_Table, col.names = c("Recording Information Variables", "Definitions"))

#GazePoint Definitions
GP_Variables <- c("gazeLeftX", "gazeLeftY", "gazeRightX","gazeRightY",
"gazeLeftX.int", "gazeLeftY.int", "gazeRightX.int", "gazeRightY.int",
"gazeX.eyeSelect", "gazeY.eyeSelect", "gazeX.smooth", "gazeY.smooth",
"gazeX.va","gazeY.va",
"gazeX.preprocessed_px", "gazeY.preprocessed_px",
"gazeX.preprocessed_va", "gazeY.preprocessed_va")
GP_Definitions <- c("Raw left eye X gaze position in pixels",
"Raw left eye Y gaze position in pixels",
"Raw right eye X gaze position in pixels",
"Raw right eye Y gaze position in pixels",
"Left eye X gaze position in pixels after interpolation",
"Left eye Y gaze position in pixels after interpolation",
"Right eye X gaze position in pixels after interpolation",
"Right eye Y gaze position in pixels after interpolation",
"Composite X gaze position after interpolation and eye selection",
"Composite Y gaze position after interpolation and eye selection",
"Composite X gaze position after interpolation, eye selection, and smoothing",
"Composite Y gaze position after interpolation, eye selection, and smoothing",
"X gaze position in visual angles",
"Y gaze position in visual angles",
"FINAL PREPROCESSED GAZE X POSITION IN PIXEL SPACE",
"FINAL PREPROCESSED GAZE Y POSITION IN PIXEL SPACE",
"FINAL PREPROCESSED GAZE X POSITION IN VISUAL ANGLE SPACE",
"FINAL PREPROCESSED GAZE Y POSITIONN IN VISUAL ANGLE SPACE")

GP_Table <- data.frame(GP_Variables, GP_Definitions)
kable(GP_Table, col.names = c("Gaze Position Variables", "Definitions"))

##Z distance table
Z_Variables <- c("distanceLeftZ", "distanceRightZ", "distanceLeftZ.int","distanceRightZ.int",
"distanceZ.eyeSelect", "distanceZ.smooth", "distanceZ.preprocessed_mm")
Z_Definitions <- c("Raw left eye Z position (distance from screen in mm)",
"Raw right eye Z position (distance from screen in mm)",
"Left eye Z position (distance from screen in mm) after interpolation",
"Right eye Z position (distance from screen in mm) after interpolation",
"Composite eye Z position (distance from screen) after interpolation and eye selection",
"Composite eye Z position (distance from screen) after interpolation, eye selection, and smoothing",
"FINAL PREPROCESSED Z DISTANCE POSITION IN MM")

Z_Table <- data.frame(Z_Variables, Z_Definitions)
kable(Z_Table, col.names = c("Z Distance Variables", "Definitions"))

#Velocity Definitions
Vel_Variables <- c("velocityX_va_ms", "velocityY_va_ms", "velocityEuclidean_va_ms",
"velocityX.smooth_va_ms", "velocityY.smooth_va_ms", "velocityEuclidean.smooth_va_ms",
"velocityX.preprocessed_va_ms", "velocityY.preprocessed_va_ms", "velocityEuclidean.preprocessed_va_ms")
Vel_Definitions <- c(
"X gaze velocity in VA/second (lagged by two gazepoints)",
"Y gaze velocity in VA/second (lagged by two gazepoints)",
"Euclidean velocity in VA/second (lagged by two gazepoints)",
"X gaze velocity in VA/second after smoothing",
"Y gaze velocity in VA/second after smoothing",
"Euclidean velocity in VA / second after smoothing",
"FINAL PREPROCESSED X GAZE VELOCITY IN VA/SECOND",
"FINAL PREPROCESSED Y GAZE VELOCITY IN VA/SECOND",
"FINAL PREPROCESSED EUCIDEAN VELOCITY IN VA/SECOND")

Vel_Table <- data.frame(Vel_Variables, Vel_Definitions)
kable(Vel_Table, col.names = c("Velocity Variables", "Definitions"))

#IVT Definitions
IVT_Variables <- c("IVT.classification", "IVT.fixationIndex", "IVT.saccadeIndex","IVT.fixationDuration_ms")
IVT_Definitions <- c("FINAL IVT FILTER CLASSIFICATION", 
  "Index number of fixation",
  "Index number of saccade",
  "Total duration of fixation (ms)")
IVT_Table <- data.frame(IVT_Variables, IVT_Definitions)
kable(IVT_Table, col.names = c("IVT Variables", "Definitions"))

#Validity Definitions
validity_Variables <- c("validLeft", "validRight", "gazeLeft.offscreen", "gazeRight.offscreen",
                        "offscreen.classification")
  
validity_Definitions <- c("Input for classifying left eye validity", "Input for classigying right eye validity",
                          "Classification of left eye offscreen gaze validity", "Classification of right eye offscreen gaze validity",
                          "FINAL CLASSIFICATION OF OVERALL OFFSCREEN VALIDITY")

validity_Table <- data.frame(validity_Variables, validity_Definitions)
kable(validity_Table, col.names = c("Validity Variables", "Definitions"))

#Pupil Definitions
Pupil_Variables <- c("pupilLeft", "pupilRight", "pupilLeft.int",
"pupilRight.int", "pupil.eyeSelect", "pupil.smooth", "pupil.preprocessed",
"pupilLeft.blink", "pupilRight.blink", "bothEyes.blink", "blink.classification")
Pupil_Definitions <- c(
"Raw left pupil data",
"Raw right pupil data",
"Interpolated left pupil data",
"Interpolated right pupil data",
"Pupil data after interpolation and eye selection",
"Pupil data after interpolation, eye selection, and smoothing",
"FINAL PREPROCESSED PUPIL DATA",
"Flags blinks in left eye (where 1 = blink)",
"Flags blinks in right eye (where 1 = blink)",
"Flags where blinks occur concurrently in both left and right eyes",
"FINAL BLINK CLASSIFICATION (based on eyeSelection method)")
Pupil_Table <- data.frame(Pupil_Variables, Pupil_Definitions)
kable(Pupil_Table, col.names = c("Pupil and Blink Variables", "Definitions"))
```


